{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dc27a3",
   "metadata": {},
   "source": [
    "## Middleware\n",
    "\n",
    "Middleware provides a way to more tightly conrol what happens inside agent.\n",
    "- Tracking agent behavior with logging, analytics, and debugging.\n",
    "- Trasforming prompts, tool selection, and output formatting.\n",
    "- Adding retries, fallbacks, and early termination logic.\n",
    "- Applying rate limits, guadrails, and Pll detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c79a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5dbcd9",
   "metadata": {},
   "source": [
    "## Summarization MiddleWare\n",
    "Automatically summarize conversatioon hisotry when approaching token limits, preserving recent messsages while compressing older context. Summarization is useful for the following:\n",
    "\n",
    "- Long-running conversations that exceed context window\n",
    "- Multi-turn dialogues with extansive history.\n",
    "- Applications where preserving full conversation context matters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fcd2ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88da33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oybek\\RAG_udemy\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "agent  = create_agent(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    checkpointer = InMemorySaver(),\n",
    "    middleware = [\n",
    "        SummarizationMiddleware(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            trigger = (\"messages\", 10),\n",
    "            keep = (\"messages\", 4)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309bff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run with thread id\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68b4e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: 10 + 3 equals 13.\n",
      "Messages: 10\n",
      "Message: 10 - 3 equals 7.\n",
      "Messages: 6\n",
      "Message: 100 divided by 3 equals approximately 33.33.\n",
      "Messages: 8\n",
      "Message: 10 - 30 equals -20.\n",
      "Messages: 10\n",
      "Message: 10 * 32 equals 320.\n",
      "Messages: 6\n"
     ]
    }
   ],
   "source": [
    "question = [\n",
    "    \"what is 10 +3\",\n",
    "    \"what is 10 -3\",\n",
    "    \"what is 100 /3\",\n",
    "    \"what is 10 -30\",\n",
    "    \"what is 10 *32\",\n",
    "]\n",
    "\n",
    "for q in question:\n",
    "    response = agent.invoke({\"messages\":[HumanMessage(content=q)]}, config)\n",
    "    print(f\"Message: {response['messages'][-1].content}\")\n",
    "    print(f\"Messages: {len(response['messages'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317a8d9",
   "metadata": {},
   "source": [
    "## Token Size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c322f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
